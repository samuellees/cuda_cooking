# cuda_matrix_multiply
Learning CUDA: Implement and optimize gemv (16384 * 2048)

### 全局内存版本
使用32个线程块*128个线程进行网格跨步，每个线程独立完成若干个结果的计算，线程之间无通信。kernel执行时间：1.96s。

### 合并访存
对矩阵进行预转置，从而使相邻线程的全局内存访问可以合并，增加访存带宽。kernel执行时间：0.53s。
另外为了防止线程进度不一致导致后面全局内存访问无法合并，尝试在每次访问线程之后进行块内同步操作，发现没有什么效果，说明统一warp内线程的进度一般是高度一致的。

### 使用常量内存
常量内存的特点是主要有两个：一是相邻线程访问同一地址会自动广播；而是高速缓存，同一地址连续操作不产生额外内存访问开销。矩阵向量乘中的向量是只读的，且相邻线程会访问同一地址，因此适合用常量内存。目前GPU中常量内存大小为64Kb=8KB，可以存放16384个float元素，若向量长度大于16384，则需要分批次计算，多次传输和启动内核。kernel执行时间：0.48s。

### 使用共享内存
共享内存比常量内存速度更快，其容量也更小，V100单卡只有48KB的共享内存，因此需要将矩阵和向量分块计算。相对于常量内存，使用共享内存可以避免多次数据传输和启动内核。具体方法是在网格跨步的基础上，块内线程每次加载一小块向量到共享内存中，所有线程加载完成后进行计算。最终若有多余的元素，则进行特殊处理。kernel执行时间：0.12s。

### 使用循环展开
使用#pragma unroll对简单循环进行展开之后，性能反而略有下降，原因尚不清楚。

### 使用shuffle指令
shuffle指令可以实现线程束内部寄存器的互相访问，速度极快。暂未尝试