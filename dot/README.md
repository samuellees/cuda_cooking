# cuda_matrix_multiply
Learning CUDA: Implement and optimize dot


### 思考
- 为什么不让每个线程处理一个元素，而是多个？
按照正常思维逻辑，应该是在硬件允许的情况下让每个线程处理一个元素；但是实际例子是线程总量固定，让每个线程处理多个元素。这样的好处是对硬件的要求比较低，并且每个线程使用一个临时寄存器变量来保存中间计算结果，往共享内存或者全局内存写回的开销少很多。另外抛开硬件的限制，如果一个线程只计算一个元素，最终还是要回到规约上。后续：这种做法称之为网格跨步。优势有：扩展性：可以解决数据量比线程数大的问题。线程复用：CUDA线程启动和销毁都有开销，主要是线程内存空间初始化的开销；不使用网格跨步，CUDA需要启动大于计算数的线程，每个线程内只做一件事情，做完就要被销毁；使用网格跨步，线程内有for循环，每个线程可以干更多事情，所有线程的启动销毁开销更少。方便边界元素的处理：若每个线程处理一个元素，则可能会遇到一个线程块内只有部分线程活跃的情况，无法使用块内同步操作。方便调试：我们可以把核函数的执行配置写为[1, 1]，如下所示，那么核函数的跨步大小就成为了1，核函数里的for循环与CPU函数中顺序执行的for循环的逻辑一样，非常方便验证CUDA并行计算与原来的CPU函数计算逻辑是否一致。（[参考链接](https://zhuanlan.zhihu.com/p/78557104)）
- 每个线程为什么处理多个不连续的元素？
这一点又与正常的思维不一致，原因在于一个线程处理多个连续的元素时，线程块整体产生的全局内存访问是不连续的，无法进行合并，会降低带宽。